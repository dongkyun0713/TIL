# 성능 기초: 응답 시간, 처리량, 커넥션 풀, 캐시

「주니어 백엔드 개발자가 반드시 알아야 할 실무 지식」 2장을 읽고 정리한 내용이다.  
API 성능을 이야기할 때 자주 등장하는 개념들을 정리했다.

---

## 1. 처리량과 응답 시간

### 1-1. 응답 시간(Response Time)

> 클라이언트가 API 요청을 보내고, JSON 응답을 모두 받을 때까지 걸린 시간

클라이언트 → 서버 요청 과정은 보통 아래 두 단계로 이뤄진다.

1. TCP를 이용해 서버에 연결
2. 정해진 프로토콜에 따라 데이터를 서버로 전송  
   예) HTTP 프로토콜 + POST 방식으로 JSON 전송

#### 응답 시간 측정 지표

- **TTFB (Time To First Byte)**  
  응답 데이터 중 **첫 번째 바이트가 도착할 때까지** 걸린 시간
- **TTLB (Time To Last Byte)**  
  응답 데이터의 **마지막 바이트가 도착할 때까지** 걸린 시간

응답 데이터가 작으면 TTFB와 TTLB의 차이가 거의 없지만,  
데이터가 크거나 네트워크가 느리면 두 값의 차이가 커진다.

응답 시간은 보통 1/1000초 단위인 `ms`를 사용한다.

서버 개발자는 이 중에서도 주로 **서버 내부 처리 시간**에 집중한다.

- 비즈니스 로직 수행
- DB 연동
- 외부 API 연동
- 응답 데이터 생성

이 중 **DB 연동**, **외부 API 연동**이 시간이 가장 크게 들기 때문에  
응답 시간을 줄이려면 이 두 부분을 우선적으로 개선해야 한다.

---

### 1-2. 처리량(Throughput)

> 단위 시간당 시스템이 처리하는 작업량

보통 아래 두 용어를 사용한다.

- **TPS (Transactions Per Second)**: 초당 트랜잭션 수
- **RPS (Requests Per Second)**: 초당 요청 수

여기서는 TPS 기준으로 이야기한다.

- **최대 TPS**: 시스템이 처리할 수 있는 최대 요청 수

최대 TPS를 초과하는 요청이 들어오면  
사용자 입장에서는 **응답 시간이 점점 길어지는 현상**이 발생한다.

예를 들어, 최대 TPS가 5인 서버에 동시에 7개의 요청이 들어오면  
5개는 바로 처리되지만, 나머지 2개는 그 다음 턴까지 기다려야 한다.

이런 상황에서 고려할 수 있는 방향은 두 가지다.

1. 서버가 동시에 처리할 수 있는 요청 수를 늘려 **대기 시간 감소**
2. 각 요청의 처리 시간을 줄여 **전체 처리량 증가**

결과적으로 두 방향 모두 TPS를 높이는 데 기여한다.

---

### 1-3. 성능을 개선하려면?

성능 개선을 논하려면 먼저 **현황 측정**이 필요하다.

- 트래픽이 많은 시간대의 TPS
- 같은 시간대의 응답 시간

을 측정하고, 이 데이터를 기반으로

- 목표 TPS
- 목표 응답 시간

을 설정한 뒤, 거기에 맞는 개선안을 도출해야 한다.

TPS를 확인하는 가장 간단한 방법은  
APM 또는 모니터링 시스템을 활용하는 것이다.

---

## 2. 성능 서버 개선 기초

### 2-1. 병목 지점(Bottleneck)

트래픽이 증가하면서 성능 문제가 발생하는 주된 이유는

> 시스템이 수용할 수 있는 최대 TPS를 초과하는 트래픽이 유입되기 때문

즉, 시스템이 제공할 수 있는 **최대 TPS를 올리지 않으면**,  
증가하는 트래픽을 제대로 처리할 수 없다.

---

### 2-2. 수직 확장과 수평 확장

#### 수직 확장(Vertical Scaling)

> 한 대의 서버에 CPU, 메모리, 디스크 등의 자원을 더 추가하는 방식

예시:

- CPU 업그레이드
- CPU 코어 수 증가
- 메모리 증설
- HDD → SSD 교체

수직 확장은 **즉각적인 효과**를 얻을 수 있어  
서비스가 이미 터져 있는 상황에서 “급한 불 끄기” 용도로 적합하다.  
다만, 트래픽이 계속 증가하면 언젠가 다시 한계에 부딪히고,  
고스펙 장비는 비용도 비싸서 무한정 확장하기 어렵다.

#### 수평 확장(Horizontal Scaling)

> 서버 대수를 늘려 부하를 분산하는 방식

서버를 여러 대 추가 투입하면 TPS를 높일 수 있지만,  
**무턱대고 서버만 늘리면 안 된다.**

예를 들어, 이미 DB가 병목인데  
DB를 사용하는 WAS 서버만 늘리면 DB 부담이 더 커져  
오히려 성능이 더 나빠질 수 있다.

따라서 DB나 외부 API에 성능 문제가 없는 범위 내에서만  
수평 확장을 해야 효과가 있다.

---

## 3. DB 커넥션 풀

### 3-1. DB 사용 기본 흐름

1. DB 연결
2. 쿼리 실행
3. 연결 종료

서버와 DB는 네트워크를 통해 통신한다.  
연결을 생성하고 종료하는 데만도 **0.5초 ~ 1초 이상** 걸릴 수 있다.

매 요청마다 DB를 새로 연결/종료하면  
트래픽이 증가할수록 처리량이 급격하게 떨어진다.

이 문제를 해결하기 위해 **DB 커넥션 풀**을 사용한다.

---

### 3-2. DB 커넥션 풀의 역할

> DB에 미리 연결된 커넥션을 여러 개 만들어서 보관해 두는 것

- 애플리케이션은 DB 작업이 필요할 때
  - 풀에서 커넥션을 하나 가져와 사용하고
  - 사용이 끝나면 다시 풀에 반환한다.
- 이미 연결된 커넥션을 재사용하므로
  - 매번 연결·종료하는 비용을 줄이고
  - 응답 시간을 단축할 수 있다.

스프링 부트는 기본적으로 **HikariCP**를 커넥션 풀로 사용한다.

커넥션 풀에서 보통 제공하는 설정:

- 커넥션 풀 크기(최소/최대)
- 풀에 커넥션이 없을 때, 대기할 최대 시간
- 커넥션의 유지 시간 관련 설정 (최대 유휴 시간, 최대 유지 시간)
- 유효성 검사 여부

---

### 3-3. 커넥션 풀 크기

> 풀에 미리 생성해 둘 커넥션 개수

예시 상황:

- 커넥션 풀 크기: 5
- 한 요청에서 쿼리 실행 시간: 1초
- 데이터 전송 시간은 무시

동시에 6개의 요청이 들어오면?

- 5개 요청: 바로 커넥션을 얻어서 처리 시작
- 1개 요청: 사용 가능한 커넥션이 없으므로,  
  누군가 반환할 때까지 대기

일반적인 커넥션 풀은 **최소 크기**와 **최대 크기**를 모두 설정한다.

예) 최소 10, 최대 20

- 동시 요청 ≤ 10 → 커넥션 10개까지만 유지
- 어느 시점에 동시 요청이 10개를 초과 → 최대 20개까지 확장
- 이후 동시 요청이 줄어들면 → 커넥션 수도 점차 줄어듦

여기서 중요한 포인트:

> “그렇다면 커넥션 풀 크기를 많이 늘리면 무조건 좋은가?”  
> → 아니다.

예를 들어 DB CPU 사용률이 이미 80%에 육박한 상황에서는  
커넥션 풀 크기를 늘리면 DB에 가해지는 부하만 증가하고  
쿼리 실행 시간이 더 느려질 수 있다.

즉, **DB 상태를 보면서 풀 크기를 조정해야 한다.**

---

### 3-4. 커넥션 대기 시간

> 풀에 사용 가능한 커넥션이 없을 때,  
> 커넥션을 얻기 위해 최대 얼마 동안 기다릴지에 대한 설정

- 이 시간을 넘기도록 커넥션을 얻지 못하면  
  → DB 연결 실패 예외 발생
- 응답 시간이 중요한 서비스라면
  → 가능한 한 짧게 설정 (예: 0.5초 ~ 3초 이내)

대기 시간을 짧게 설정하면:

- 커넥션이 모두 사용 중일 때,  
  오래 기다리기보다 빠르게 “일시적 오류” 응답을 줄 수 있다.
- 무한 대기 상태로 서버 자원이 묶이는 것을 방지하고  
  전체 부하 증가를 막을 수 있다.

---

### 3-5. 최대 유휴 시간, 유효성 검사, 최대 유지 시간

요청이 거의 없는 시간대에는  
풀에 있는 커넥션들이 오랫동안 사용되지 않을 수 있다.

DB는 보통

> 일정 시간 동안 아무 요청도 오지 않으면  
> 유휴 커넥션을 자동으로 끊는 기능

을 제공한다.

그런데, DB는 이미 끊었는데 커넥션 풀은 그 사실을 모르면  
끊긴 커넥션을 다시 사용하려다 에러가 발생할 수 있다.

이 문제를 막기 위해 커넥션 풀은 다음 기능들을 제공한다.

---

#### (1) 최대 유휴 시간(Idle Timeout)

> “안 쓰고 가만히 있는 커넥션을 얼마나 오래 살려둘까?”를 정하는 값

- 예) 30분으로 설정했다면  
  → 30분 동안 사용되지 않은 커넥션은 풀에서 제거된다.
- 이 시간을 **DB가 유휴 연결을 끊는 시간보다 짧게** 설정해 두면
  - DB가 먼저 연결을 끊는 상황을 줄일 수 있고
  - 끊긴 커넥션을 다시 쓰려다가 터지는 문제를 예방할 수 있다.

---

#### (2) 유효성 검사(Validation)

> “빌려주기 전에 이 커넥션이 정말 멀쩡한지 확인하는 과정”

- 커넥션 풀은 DB 연결을 계속 재사용한다.
- 오랫동안 유휴 상태였던 커넥션은 이미 DB가 끊었을 가능성이 있다.
- 그래서 애플리케이션에 커넥션을 빌려주기 전에
  - 가벼운 쿼리나 `isValid()` 호출로 “살아있는지” 확인한다.
- 응답이 없거나 에러가 나면
  - 해당 커넥션은 폐기하고
  - 새 커넥션을 만들어 대체한다.

이 과정을 통해

> 끊어진 커넥션을 애플리케이션에 전달하는 일을 막고  
> Broken pipe 같은 오류를 사전에 방지할 수 있다.

---

#### (3) 최대 유지 시간(Max Lifetime)

> “커넥션이 살아 있을 수 있는 최대 수명”

- DB 커넥션은 한 번 만들면 계속 재사용되지만,
  - 너무 오래된 커넥션은 내부적으로 문제가 생기거나,
  - 네트워크 변화 등으로 불안정해질 가능성이 높다.
- 그래서 커넥션 풀은 일정 시간이 지나면
  - “이 커넥션은 너무 오래됐다. 교체하자.”  
    라고 판단하고
  - 해당 커넥션을 스스로 종료한 뒤, 새로운 커넥션으로 교체한다.

> 최대 유지 시간은 “쓰든 말든 상관없이, 생성된 지 얼마가 지나면 교체할지”를 정하는 절대 수명에 가깝다.

---

#### (4) Idle Timeout vs Max Lifetime 정리

- **최대 유휴 시간(Idle Timeout)**  
  → “안 쓰고 가만히 있는” 커넥션의 수명  
- **최대 유지 시간(Max Lifetime)**  
  → “쓰든 말든” 모든 커넥션의 절대 수명

둘 다 무제한으로 두기보다는  
DB 설정(유휴 시간, 세션 최대 시간 등)을 참고하여  
적절한 값으로 지정하는 것이 좋다.

---

## 4. 서버 캐시

DB 서버 확장은 비용이 많이 든다.  
DB를 확장하면 **처리량**은 늘릴 수 있지만,  
**응답 시간**을 획기적으로 줄이기는 어렵다.

이때 고려할 수 있는 것이 **캐시**다.  
캐시는 보통 DB보다 훨씬 빠르기 때문에  
자주 조회되는 데이터를 캐시에 보관하면 응답 시간을 줄일 수 있다.

일반적인 캐시 읽기 흐름:

1. 먼저 캐시에서 키에 해당하는 값을 조회
2. 값이 있으면 → 그대로 사용
3. 값이 없으면 → DB에서 조회 후 캐시에 저장, 그 값을 반환

---

### 4-1. 캐시 적중률과 삭제 규칙

> 캐시가 얼마나 효율적으로 사용되는지 = **캐시 적중률**

- 적중률 = `캐시에 존재한 건수 / 캐시 조회 시도 건수`

적중률을 높이려면 가능한 많은 데이터를 캐시에 저장하고 싶지만,  
메모리는 한정적이므로 **삭제 정책**이 필요하다.

대표적인 삭제 규칙:

- **LRU (Least Recently Used)**  
  가장 오래 사용되지 않은 데이터를 제거
- **LFU (Least Frequently Used)**  
  가장 적게 사용된 데이터를 제거
- **FIFO (First In First Out)**  
  먼저 들어온 데이터를 먼저 제거

---

### 4-2. 로컬 캐시와 리모트 캐시

서버 캐시는 크게 두 종류로 나눌 수 있다.

1. **로컬 캐시(Local Cache)**  
   - 서버 프로세스와 같은 메모리를 사용하는 캐시
2. **리모트 캐시(Remote Cache)**  
   - 별도의 프로세스(예: Redis)를 캐시 저장소로 사용하는 방식

#### 로컬 캐시

- 장점
  - 서버 프로세스와 같은 메모리에 있기 때문에 매우 빠르다.
- 단점
  - 서버 프로세스가 사용할 수 있는 메모리 한계에 영향을 받는다.
  - 서버 프로세스 재시작 시, 캐시 데이터가 모두 날아간다.

#### 리모트 캐시

- 장점
  - 캐시 용량을 유연하게 확장 가능 (예: Redis 클러스터)
  - 서버 재시작과 무관하게 캐시 데이터 유지 가능
- 단점
  - 네트워크 통신이 필요해 로컬 캐시보다 느리다.
  - 별도의 서버와 프로세스를 운영해야 하므로 시스템 구조가 복잡해진다.

정리하면:

- 자주 바뀌지 않고 크기가 작은 데이터 → 로컬 캐시 적합
- 데이터 규모가 크고, 배포 빈도가 높은 서비스 → 리모트 캐시 적합

---

### 4-3. 캐시 사전 적재

> 트래픽이 특정 시간에 몰리는 패턴이 있다면,  
> “미리 캐시를 채워 두는 것”도 좋은 전략이다.

예시 상황:

- G 앱 사용자는 300만 명
- 매달 정해진 날에 “이달의 요금 정보”를 보여준다.
- 해당 일자에 전체 회원에게 푸시 알림 발송
- 푸시를 받은 사용자 중 일부가 요금 정보를 확인

만약 푸시 직후 50%가 곧바로 접속한다면  
짧은 시간에 150만 명이 동시에 요금 정보를 조회할 수 있다.

이때 요금 정보가 캐시에 없다면  
순간적으로 캐시 적중률이 0%에 가깝게 떨어지고  
DB에 엄청난 부하가 걸린다.

해결 방법:

- 푸시를 보내기 전에 미리 요금 정보를 캐시에 적재해 두면  
  트래픽이 몰리는 시점에도 캐시 적중률을 높게 유지할 수 있다.

---

### 4-4. 캐시 무효화(Cache Invalidation)

캐시 사용 시 항상 신경 써야 할 부분:

> 원본 데이터가 바뀌었을 때,  
> 캐시 데이터를 어떻게 갱신하거나 삭제할 것인가?

- 원본이 변경됐는데 캐시가 갱신되지 않으면  
  사용자에게 잘못된/오래된 데이터를 보여줄 수 있다.

변경에 민감한 데이터는

- 로컬 캐시보다 리모트 캐시에 두는 것이 안전하다.
- 로컬 캐시는 각 서버별로 따로 존재하기 때문에  
  한 서버에서만 캐시를 지우면 다른 서버의 캐시는 여전히 옛 데이터를 들고 있을 수 있다.

변경에 민감하지 않고 크기가 작다면

- 캐시 유효 시간(TTL)을 설정해,  
  일정 주기마다 자연스럽게 갱신되도록 하는 전략도 사용할 수 있다.  
  예) “최근 인기 글 목록”

---

## 5. 가비지 컬렉터와 메모리 사용

GC를 사용하는 언어(예: Java)는  
사용이 끝난 객체를 바로 삭제하지 않고,  
일정 규칙에 따라 사용하지 않는 객체를 찾아 메모리를 회수한다.

예:

- 힙 메모리 사용량이 일정 비율을 초과할 때
- 일정 시간 주기마다 자동 실행할 때

장점:

- 개발자가 메모리를 직접 관리하지 않아도 된다.
- 잘못된 메모리 접근으로 인한 보안 이슈를 줄일 수 있다.

단점:

- GC가 실행되는 동안 애플리케이션이 일시 중단될 수 있다.
- 이 중단 시간이 응답 시간에 영향을 줄 수 있다.

따라서:

- 메모리를 많이 쓰고, 객체 생성/삭제가 많을수록  
  GC가 처리해야 할 대상이 많아지고  
  GC 수행 시간이 길어진다.
- 반대로 메모리 사용을 줄이면  
  GC가 처리할 대상이 줄어들어 GC 시간도 줄어든다.

다만, 메모리를 너무 제한하면  
OutOfMemoryError가 날 수 있으므로  
**애플리케이션의 메모리 사용 패턴에 맞는 힙 크기 설정**이 필요하다.

---

## 6. 응답 데이터 압축

응답 시간에는 **데이터 전송 시간**도 포함된다.

전송 시간은 크게 두 가지 요인의 영향을 받는다.

1. 네트워크 속도 (통제하기 어려움)
2. 전송 데이터 크기 (우리가 줄일 수 있음)

텍스트 데이터(JSON, HTML 등)는 gzip으로 압축할 경우  
보통 70% 이상 크기를 줄일 수 있다.

장점:

- 응답 시간이 단축될 수 있다.
- 전송량이 줄어들어 트래픽 비용을 절감할 수 있다.

Nginx 같은 웹 서버, 혹은 애플리케이션 서버는  
보통 gzip과 같은 압축 기능을 기본으로 제공한다.

---

## 7. 대기 처리(Queueing)

짧은 시간 동안 폭증하는 트래픽은  
단순히 서버를 증설하는 것만으로 해결되지 않을 수 있다.

- 트래픽 증가는 WAS뿐 아니라 DB에도 영향을 준다.
- DB 스펙을 크게 늘리면 비용 부담이 크고,  
  한 번 늘린 성능을 다시 줄이기도 쉽지 않다.

그래서

> 시스템이 감당할 수 있는 수준까지만 요청을 받고,  
> 나머지는 “대기열”로 넘기는 전략

도 고려할 수 있다.

장점:

- 서버 자원을 과도하게 증설하지 않고도  
  서비스를 안정적으로 제공할 수 있다.
- 사용자의 무한 새로고침으로 인한 폭발적인 트래픽을 방지할 수 있다.  
  (새로고침 시 대기열이 뒤로 밀리는 구조라면 사용자가 오히려 새로고침을 줄이게 된다.)

---

이 정리는 “성능”을 이야기할 때 기반이 되는 개념들을  
한 번에 묶어 이해하기 위한 목적이다.  
실제 프로젝트를 할 때는

- 현재 TPS / 응답 시간 측정
- DB · 외부 API 병목 확인
- 커넥션 풀 설정 점검
- 캐시 전략 설계
- GC 튜닝, 힙 사이즈 점검

같은 항목들을 체크리스트처럼 점검하면 좋을 것 같다.
